# ğŸ”¬ DOCUMENTATION - Strategy Backtest

## ğŸ¯ Vue d'ensemble

Ce script implÃ©mente des stratÃ©gies d'allocation **avancÃ©es** qui amÃ©liorent Markowitz en rÃ©duisant l'instabilitÃ© et les coÃ»ts de transaction.

**Fichier :** `shrinkage_hrp.py`

**StratÃ©gies testÃ©es :**
1. Risk Parity Simple (Inverse Volatility)
2. Risk Parity + Shrinkage Ledoit-Wolf
3. Hierarchical Risk Parity (HRP)
4. HRP + Shrinkage
5. Markowitz Standard
6. Markowitz + Shrinkage

---

## ğŸ“‹ Table des matiÃ¨res

1. [Architecture](#architecture)
2. [Configuration](#configuration)
3. [ThÃ©orie des stratÃ©gies](#theorie)
4. [Blocs de code dÃ©taillÃ©s](#blocs)
5. [MathÃ©matiques](#maths)
6. [InterprÃ©tation rÃ©sultats](#interpretation)

---

## ğŸ—ï¸ Architecture {#architecture}

```
shrinkage_hrp.py
â”œâ”€â”€ IMPORTS & CONFIG (lignes 1-60)
â”œâ”€â”€ UTILITIES (lignes 61-150)
â”œâ”€â”€ SHRINKAGE LEDOIT-WOLF (lignes 151-200)
â”œâ”€â”€ HRP - HIERARCHICAL RISK PARITY (lignes 201-350)
â”œâ”€â”€ STRATÃ‰GIES CLASSIQUES (lignes 351-450)
â”œâ”€â”€ BACKTEST GÃ‰NÃ‰RIQUE (lignes 451-600)
â”œâ”€â”€ MÃ‰TRIQUES (lignes 601-700)
â”œâ”€â”€ VISUALISATIONS (lignes 701-950)
â””â”€â”€ MAIN (lignes 951-1100)
```

---

## âš™ï¸ Configuration {#configuration}

```python
CONFIG = {
    # Portfolio
    'tickers': ['AAPL', 'MSFT', 'GOOGL', ...],
    'date_debut': '2018-01-01',
    'date_fin': '2025-12-31',
    
    # Backtest
    'fenetre_estimation': 252,      # Rolling window
    'frequence_rebalancement': 21,  # Mensuel
    'cout_transaction': 0.001,      # 0.1%
    
    # Finance
    'taux_sans_risque': 0.02,
    'capital_initial': 100000,
}
```

---

## ğŸ“š ThÃ©orie des stratÃ©gies {#theorie}

### **1. Risk Parity Simple (Inverse Volatility)**

**Principe :**
```
Plus un actif est volatile, moins on en prend
```

**Formule :**
```python
w(i) = (1 / Ïƒ(i)) / Î£(1 / Ïƒ(j))
```

**Avantages :**
- âœ… Ultra simple
- âœ… TrÃ¨s stable (turnover ~5%)
- âœ… CoÃ»ts faibles
- âœ… Robuste

**InconvÃ©nients :**
- âš ï¸ Ignore les rendements
- âš ï¸ Ignore les corrÃ©lations

---

### **2. Shrinkage Ledoit-Wolf**

**ProblÃ¨me rÃ©solu :**
```
Matrice de covariance empirique = BRUITÃ‰E

Exemple :
Cov(AAPL, MSFT) estimÃ©e = 0.045
Vraie covariance          = 0.040
Erreur                    = +12%
```

**Solution :**
```
Î£_shrunk = Î´ Ã— F + (1-Î´) Ã— S

oÃ¹ :
S = matrice empirique (bruitÃ©e)
F = matrice cible (structurÃ©e)
Î´ = intensitÃ© de shrinkage (auto-optimisÃ©e)
```

**Quand utile ?**
- Beaucoup d'actifs (50+)
- Peu de donnÃ©es (<100 jours)
- Matrice trÃ¨s bruitÃ©e

**Constat de nos tests :**
```
Î´ moyen = 0.001 â†’ QUASI NUL !
Raison : 10 actifs + 252 jours = donnÃ©es suffisantes
```

---

### **3. Hierarchical Risk Parity (HRP)**

**Principe :**
```
Allouer en 2 temps :
1. Entre CLUSTERS (Tech, Finance, SantÃ©)
2. Dans CHAQUE cluster
```

**Algorithme (Marcos LÃ³pez de Prado, 2016) :**

**Ã‰TAPE 1 : Clustering**
```python
Distance(i,j) = âˆš(0.5 Ã— (1 - Corr(i,j)))
Clustering hiÃ©rarchique â†’ Dendrogram
```

**Ã‰TAPE 2 : Quasi-diagonalisation**
```
RÃ©organiser la matrice de covariance pour regrouper
les actifs similaires ensemble
```

**Ã‰TAPE 3 : Allocation rÃ©cursive**
```
Fonction rÃ©cursive :
1. Diviser cluster en 2 sous-clusters
2. Allouer entre les 2 (inverse variance)
3. RÃ©pÃ©ter sur chaque sous-cluster
```

**Exemple concret :**
```
Portfolio [AAPL, MSFT, GOOGL, JPM, BAC, JNJ]

Clustering :
â”œâ”€ Tech [AAPL, MSFT, GOOGL]
â”œâ”€ Finance [JPM, BAC]
â””â”€ SantÃ© [JNJ]

Allocation niveau 1 :
Tech    : 40%
Finance : 35%
SantÃ©   : 25%

Allocation niveau 2 :
AAPL  : 40% Ã— 0.33 = 13%
MSFT  : 40% Ã— 0.33 = 13%
GOOGL : 40% Ã— 0.34 = 14%
JPM   : 35% Ã— 0.55 = 19%
BAC   : 35% Ã— 0.45 = 16%
JNJ   : 25% Ã— 1.00 = 25%
```

**Avantages :**
- âœ… Diversification VRAIE (sectorielle)
- âœ… Stable (turnover ~15%)
- âœ… Meilleur drawdown en crise
- âœ… Pas de matrice Ã  inverser

**InconvÃ©nients :**
- âš ï¸ ComplexitÃ© algorithmique
- âš ï¸ Turnover > Risk Parity Simple
- âš ï¸ CoÃ»ts 3Ã— plus Ã©levÃ©s

---

## ğŸ”§ Blocs de code dÃ©taillÃ©s {#blocs}

### **BLOC 1 : Shrinkage Ledoit-Wolf**

```python
def ledoit_wolf_shrinkage(rendements):
```

**ImplÃ©mentation :**

**1. Matrice empirique**
```python
S = np.cov(rendements.T, bias=True)
```

**2. Matrice cible (constant correlation)**
```python
var_mean = np.trace(S) / n_actifs
corr_mean = (np.sum(S) - np.trace(S)) / (n Ã— (n-1))
F = corr_mean Ã— ones((n,n))
F[diagonal] = var_mean
```

**3. IntensitÃ© de shrinkage**
```python
diff = S - F
delta = min(1, max(0, np.sum(diffÂ²) / (n_obs Ã— np.sum(SÂ²))))
```

**4. Matrice shrunk**
```python
S_shrunk = delta Ã— F + (1 - delta) Ã— S
```

**Retour :**
```python
return S_shrunk, delta
```

---

### **BLOC 2 : HRP - Partie A (Clustering)**

```python
def get_quasi_diag(link):
```

**Ce qu'il fait :**
1. Prend la sortie de `scipy.cluster.hierarchy.linkage`
2. Extrait l'ordre optimal des actifs
3. Retourne indices pour rÃ©organiser la matrice

**Algorithme rÃ©cursif :**
```python
Tant que (il reste des clusters fusionnÃ©s):
    Remplacer cluster_id par ses 2 enfants
    Trier par index
```

---

### **BLOC 3 : HRP - Partie B (Allocation)**

```python
def hrp_allocation(rendements, matrice_cov):
```

**Ã‰tapes :**

**1. Clustering**
```python
corr = rendements.corr()
dist = np.sqrt(0.5 Ã— (1 - corr))
link = linkage(squareform(dist), method='single')
```

**2. RÃ©organisation**
```python
sort_ix = get_quasi_diag(link)
cov_sorted = matrice_cov.loc[sort_ix, sort_ix]
```

**3. Allocation rÃ©cursive**
```python
weights = Series(1.0)  # Tous Ã  100% au dÃ©part
clusters = [all_assets]

while len(clusters) > 0:
    for cluster in clusters:
        # Split en 2
        left = cluster[:len//2]
        right = cluster[len//2:]
        
        # Variance de chaque moitiÃ©
        var_left = cluster_variance(left)
        var_right = cluster_variance(right)
        
        # Allouer inverse variance
        alpha = 1 - var_left / (var_left + var_right)
        
        weights[left] *= alpha
        weights[right] *= (1 - alpha)
```

---

### **BLOC 4 : Backtest gÃ©nÃ©rique**

```python
def backtest_strategie(prix, fenetre, frequence_rebal, 
                       strategie='rp_simple', use_shrinkage=False):
```

**Architecture :**

**1. Initialisation**
```python
valeur_portfolio = Series(index=rendements.index)
valeur_portfolio[0] = CAPITAL_INITIAL
poids_actuels = array([1/n] * n)
```

**2. Boucle quotidienne**
```python
for jour in range(1, len(rendements)):
    # Rendement quotidien
    rdt_jour = rendements.iloc[jour]
    valeur_portfolio[jour] = valeur_portfolio[jour-1] Ã— (1 + rdt_pf)
    
    # Drift naturel des poids
    poids_actuels = poids_actuels Ã— (1 + rdt_jour)
    poids_actuels /= sum(poids_actuels)  # Re-normaliser
    
    jours_depuis_rebal += 1
```

**3. Rebalancement (tous les 21 jours)**
```python
if jours_depuis_rebal >= 21 and jour >= 252:
    # FenÃªtre roulante
    rendements_fenetre = rendements[jour-252:jour]
    
    # Covariance (avec ou sans shrinkage)
    if use_shrinkage:
        matrice_cov, delta = ledoit_wolf_shrinkage(...)
    else:
        matrice_cov = rendements_fenetre.cov() Ã— 252
    
    # Calculer nouveaux poids
    if strategie == 'rp_simple':
        poids = inverse_volatility(...)
    elif strategie == 'hrp':
        poids = hrp_allocation(...)
    elif strategie == 'markowitz':
        poids = optimize_sharpe(...)
    
    # Turnover et coÃ»ts
    turnover = sum(|poids_nouveaux - poids_actuels|)
    cout = turnover Ã— 0.001 Ã— valeur_portfolio[jour]
    valeur_portfolio[jour] -= cout
    
    # Appliquer
    poids_actuels = poids_nouveaux
    jours_depuis_rebal = 0
```

**ParticularitÃ© importante :**
```python
# PAS de look-ahead bias !
# On utilise UNIQUEMENT les donnÃ©es jusqu'Ã  jour-1
rendements_fenetre = rendements[jour-252:jour]
```

---

### **BLOC 5 : MÃ©triques de performance**

```python
def calculer_metriques_performance(...):
```

**MÃ©triques calculÃ©es :**

**1. Rendement total et annualisÃ©**
```python
rendement_total = (valeur_finale / valeur_initiale) - 1
n_annees = n_jours / 252
rendement_annualise = (1 + rendement_total) ** (1/n_annees) - 1
```

**2. VolatilitÃ©**
```python
rendements_quotidiens = valeur_portfolio.pct_change()
volatilite = rendements_quotidiens.std() Ã— âˆš252
```

**3. Sharpe Ratio**
```python
sharpe = (rendement_annualise - 0.02) / volatilite
```

**4. Maximum Drawdown**
```python
cummax = valeur_portfolio.cummax()
drawdown = (valeur_portfolio - cummax) / cummax
max_drawdown = drawdown.min()
```

**5. Turnover moyen**
```python
turnover_moyen = mean(historique_turnover)
```

**6. CoÃ»ts totaux**
```python
couts_totaux = sum(historique_couts)
pct_couts = couts_totaux / capital_initial
```

---

### **BLOC 6 : Visualisations**

```python
def visualiser_comparaison_complete(resultats, prix):
```

**7 graphiques gÃ©nÃ©rÃ©s :**

**1. Performance comparÃ©e**
- Courbe de la valeur du portfolio
- Une couleur distincte par stratÃ©gie
- LÃ©gende en 3 colonnes

**2. Drawdown**
- % de perte depuis le pic
- Montre la souffrance en crise

**3. VolatilitÃ© roulante (63 jours)**
- Montre si le risque est stable
- DÃ©tecte les pÃ©riodes volatiles

**4. Sharpe roulant (252 jours)**
- Performance ajustÃ©e au risque dans le temps
- Montre quelle stratÃ©gie est robuste

**5. Turnover cumulÃ©**
- Volume de trading total
- Visualise le coÃ»t du rebalancement

**6. Tableau comparatif**
- Toutes les mÃ©triques
- Noms abrÃ©gÃ©s pour lisibilitÃ©
- Highlight des meilleurs (vert)

**7. Rendements annuels**
- Barres par annÃ©e
- Montre quelle stratÃ©gie domine quand

---

## ğŸ“ MathÃ©matiques {#maths}

### **1. Distance pour clustering**

```
D(i,j) = âˆš(0.5 Ã— (1 - Ï(i,j)))

oÃ¹ Ï = corrÃ©lation
```

**PropriÃ©tÃ©s :**
- Ï = 1 â†’ D = 0 (trÃ¨s similaires)
- Ï = 0 â†’ D = 0.707
- Ï = -1 â†’ D = 1 (opposÃ©s)

---

### **2. Variance d'un cluster**

```
Var(cluster) = w_cluster^T Ã— Î£_cluster Ã— w_cluster

oÃ¹ w_cluster = poids inverse variance dans le cluster
```

---

### **3. Allocation entre 2 clusters**

```
Î± = 1 - Var(left) / (Var(left) + Var(right))

w(left) = Î±
w(right) = 1 - Î±
```

**InterprÃ©tation :**
- Si Var(left) < Var(right) â†’ Î± > 0.5 â†’ plus de poids Ã  gauche

---

### **4. Inverse Volatility Weighting**

```
w(i) = (1/Ïƒ(i)) / Î£_j(1/Ïƒ(j))

Normalisation :
Î£_i w(i) = 1
```

---

## ğŸ“Š InterprÃ©tation des rÃ©sultats {#interpretation}

### **Classement Sharpe Ratio**

```
> 1.0  : Excellent (2012-2015 bull market)
0.7-1.0: Bon      (2016-2020 avec COVID)
0.5-0.7: Moyen    (PÃ©riode volatile)
< 0.5  : MÃ©diocre
```

---

### **Classement Drawdown**

```
< -20% : Faible   (TrÃ¨s bon)
-20 Ã  -30% : ModÃ©rÃ©  (Acceptable)
-30 Ã  -40% : Ã‰levÃ©   (Douloureux)
> -40% : SÃ©vÃ¨re  (Catastrophique)
```

---

### **Classement Turnover**

```
< 10%  : Ultra faible (RP Simple)
10-20% : Faible       (HRP)
20-40% : ModÃ©rÃ©       (RP OptimisÃ©)
> 40%  : Ã‰levÃ©        (Markowitz)
```

---

### **Classement CoÃ»ts (sur 7 ans, $100k)**

```
< $1,000   : Excellent (RP Simple)
$1-3k      : Bon       (HRP)
$3-5k      : Moyen
> $5k      : Ã‰levÃ©     (Markowitz)
```

---

## ğŸ¯ Guide de dÃ©cision

### **Choisir Risk Parity Simple si :**
- âœ… Tu veux la simplicitÃ©
- âœ… Tu veux minimiser les coÃ»ts
- âœ… Tu acceptes drawdown moyen
- âœ… Tu veux robustesse

### **Choisir HRP si :**
- âœ… Tu veux meilleur drawdown
- âœ… Tu comprends le clustering
- âœ… Tu acceptes coÃ»ts 3Ã— plus Ã©levÃ©s
- âœ… Tu trades sur crises

### **Choisir Markowitz si :**
- âœ… Tu veux rendement maximum
- âœ… Tu acceptes turnover fou
- âœ… Tu acceptes coÃ»ts Ã©levÃ©s
- âœ… Tu es sophistiquÃ©

---

## âš ï¸ PiÃ¨ges Ã  Ã©viter

### **1. Shrinkage inutile dans nos tests**
```
Î´ = 0.001 â†’ Aucun effet
Raison : 10 actifs + 252 jours = suffisant

Si tu veux voir shrinkage fonctionner :
- Utilise 50+ actifs
- OU rÃ©duis fenÃªtre Ã  100 jours
```

### **2. HRP sensible au nombre d'actifs**
```
Minimum : 6 actifs
Optimal : 10-20 actifs
Maximum : ~50 actifs

Trop peu â†’ Pas de clusters intÃ©ressants
Trop â†’ Clustering confus
```

### **3. FenÃªtre d'estimation**
```
Trop courte (<100j) â†’ Bruit
Trop longue (>500j) â†’ Pas adaptatif

Sweet spot : 252 jours (1 an)
```

---

## ğŸ”¬ RÃ©sultats empiriques (nos tests)

### **SynthÃ¨se 4 pÃ©riodes testÃ©es :**

| StratÃ©gie | Sharpe moyen | Drawdown moyen | CoÃ»ts moyens | Turnover |
|-----------|--------------|----------------|--------------|----------|
| **RP Simple** | **0.84** ğŸ¥‡ | -27% | **$640** ğŸ¥‡ | **5%** ğŸ¥‡ |
| **HRP** | 0.81 | **-25%** ğŸ¥‡ | $1,900 | 15% |
| **Markowitz** | 0.73 | -31% | $5,800 | 43% |

**Verdict :**
```
Risk Parity Simple = GAGNANT GÃ‰NÃ‰RAL
- Meilleur Sharpe
- CoÃ»ts ridicules
- Ultra stable
```

---

## ğŸš€ Utilisation

### **Test standard**

```bash
python shrinkage_hrp.py
```

### **Changer pÃ©riode**

```python
CONFIG = {
    'date_debut': '2020-01-01',
    'date_fin': '2025-12-31',
}
```

### **Changer portfolio**

```python
CONFIG = {
    'tickers': ['SPY', 'TLT', 'GLD', 'VNQ', 'IEF'],
}
```

---

## ğŸ“š RÃ©fÃ©rences acadÃ©miques

**Risk Parity :**
- Qian, E. (2005). "Risk Parity Portfolios"
- Asness et al. (2012). "Leverage Aversion and Risk Parity"

**HRP :**
- LÃ³pez de Prado, M. (2016). "Building Diversified Portfolios that Outperform Out of Sample"

**Shrinkage :**
- Ledoit, O. & Wolf, M. (2004). "Honey, I Shrunk the Sample Covariance Matrix"

---

## ğŸ› Troubleshooting

**ProblÃ¨me : HRP IndexError**
```
Solution : VÃ©rifier que get_quasi_diag() retourne des entiers
```

**ProblÃ¨me : Shrinkage Î´ = 0**
```
Normal si peu d'actifs + beaucoup de donnÃ©es
```

**ProblÃ¨me : Turnover trop Ã©levÃ©**
```
Augmenter frequence_rebalancement Ã  63 (trimestriel)
```

---

**Fin de la documentation - Version 1.0**
